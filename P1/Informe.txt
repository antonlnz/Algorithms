Autores: Carlos Martinez Rabunal y Anton Lopez Nuñez.

Todas las referencias a tiempos estan expresados en microsegundos, a no ser que se indique lo contrario.

Los algoritmos han sido ejecutados en un ordenador con las siguientes caracteristicas:
	Procesador: Intel i7 1165G7 2.80GHz
	Memoria RAM: 12GB
	Fabricante: HP
	Sistema Operativo: Ubuntu 22.04

En este informe se exponen los resultados del estudio de 3 algoritmos que
permiten calcular el termino n-esimo de la sucesión de fibonaci. 
El objetivo es comprobar empiricamente el analisis teorico de la eficiencia
de dichos algoritmos, familiarizarse con la medicion de tiempos y comparar su eficiencia.

En primer lugar, tras implementar los tres algoritmos y comprobar
que calculan los 10 primeros elementos de la Sucesion de Fibonacci correctamente (ver tabla 1),
pasamos a realizar las mediciones del tiempo de ejecucion de cada algoritmo para unos numeros (n) dados.

(Tabla 1): Se imprime el elemento n-esimo de la sucesion de Fibonacci empleando los3 algoritmos.
n	fib1(n)	fib2(n)	fib3(n)
1	   1	   1	   1
2	   1	   1	   1
3	   2	   2	   2
4	   3	   3	   3
5	   5	   5	   5
6	   8	   8	   8
7	  13	  13	  13
8	  21	  21	  21
9	  34	  34	  34
10	  55	  55	  55

Dichos tiempos corresponden con la segunda columna de las tablas fib1, fib2 y fib3 y han sido empleados para
encontrar las cotas de las columnas posteriores:
- Col. 3. t(n)/f(n): donde f(n) es una cota ligeramente subestimada.
- Col. 4. t(n)/g(n): donde g(n) es una cota ajustada.
- Col. 5. t(n)/h(n): donde h(n) es una cota ligeramente sobrestimada.

Con el objetivo de evitar mediciones anomalas, hemos empleado un umbral de confianza de 500 microsegundos,
para que, en el caso de que se midan tiempos menores, se ejecuten 1000 veces (K) para obtener un promedio algo mas 
fiable (filas con *).

En el primer algoritmo (fib1) empleamos una cota subestimada de 1.1^n, una cota ajustada de phi^n (aprox. 1.62^n) y una cota sobrestimada de 2^n. 

Algoritmo fib1: K = 1000
n          t(n)            t(n)/f(n)       t(n)/g(n)       t(n)/h(n)        
2          0.019000 *      0.015702        0.007257        0.004750       
4          0.061000 *      0.041664        0.008900        0.003812       
8          0.457000 *      0.213194        0.009728        0.001785       
16         8.019000 *      1.745168        0.003633        0.000122       
32         12873.000000    609.696700      0.002643        0.000003

Podemos apreciar que la cota ajustada en esta medicion no tiende a una constante determinada, con lo cual elevaremos 
las repeticiones de 1000 a 1000000 de iteraciones, obteniendo la siguiente tabla:

Algoritmo fib1: k = 1000000
n          t(n)            t(n)/f(n)       t(n)/g(n)       t(n)/h(n)        
2          0.008064        0.006664        0.003080        0.002016       
4          0.016423        0.011217        0.002396        0.001026       
8          0.119259        0.055635        0.002539        0.000466       
16         5.596587        1.217980        0.002536        0.000085       
32         12374.000000    586.062842      0.002540        0.000003

En este segundo intento, vemos tiempos de ejecucion menores y la cota ajustada tiende a los 2.5 ms.

En el segundo algoritmo (fib2) empleamos una cota subestimada de (n^0.8), una cota ajustada
de n y una cota sobrestimada de (n*log(n))

Algoritmo fib2: k = 1000
n          t(n)            t(n)/f(n)       t(n)/g(n)       t(n)/h(n)     
1000       1.565000 *      0.006230        0.001565        0.000522       
10000      16.066000 *     0.010137        0.001607        0.000402       
100000     156.489000 *    0.015649        0.001565        0.000313       
1000000    1664.000000     0.026373        0.001664        0.000277       
10000000   16997.000000    0.042695        0.001700        0.000243

Podemos apreciar que la cota ajustada tiende a la constante 1.6 ms y que las cotas subestimada y 
sobrestimada crecen y decrecen respectivamente.

Por ultimo, en el tercer algoritmo (fib3) empleamos una cota subestimada de sqrt(log(n)), una cota ajustada
de log(n) y una cota sobrestimada de (n^0.5)

Algoritmo fib3: K = 1000
n          t(n)            t(n)/f(n)      t(n)/g(n)      t(n)/(n^0.5)       
1000       0.119000        0.068705        0.039667        0.003763       
10000      0.150000        0.075000        0.037500        0.001500       
100000     0.184000        0.082287        0.036800        0.000582       
1000000    0.227000        0.092672        0.037833        0.000227       
10000000   0.263000        0.099405        0.037571        0.000083

Aunque con menos claridad que en fib2, la cota ajustada de fib3 tiende a una constante aproximada de 37.5 ms y las cotas
subestimada y sobrestimada crecen y decrecen respectivamente. Asimismo, al repetir el algoritmo con una K = 1000000, como en el 
primer caso, obtenemos unos tiempos de ejecucion y una constante mucho menores. Por lo que consideramos este primer estudio como
una anomalia.

Algoritmo fib3: K = 1000000
n          t(n)            t/sqrt(log(n))  t/log(n)        t/(n^0.5)       
1000       0.037867        0.021863        0.012622        0.001197       
10000      0.043051        0.021525        0.010763        0.000431       
100000     0.052560        0.023506        0.010512        0.000166       
1000000    0.065774        0.026852        0.010962        0.000066       
10000000   0.073757        0.027878        0.010537        0.000023

En este segundo intento, vemos unos tiempos mas coherentes con este algoritmo, llegando a ser mas rapido que los anteriores.
La cota ajustada es tiende ahora a los 10.5 ms y sus resultados son mas homogeneos.




La complejidad teorica sigue el siguiente orden (de menos complejo a mas complejo):
    fib3 (Complejidad logaritmica)
    fib2 (Complejidad lineal)
    fib1 (Complejidad exponencial)
    
Y la complejidad empirica observada para K = 1000 y para K = 1000000 sigue este orden:

Para K = 1000: (menor tiempo de ejecucion a mayor tiempo de ejecucion)
    fib2, fib1, fib3.
    
Para K = 10000000: (menor tiempo de ejecucion a mayor tiempo de ejecucion)
    fib3, fib2, fib1.
    
Por ende, se puede concluir que cuantas mas repeticiones hagamos de los tiempos que no llegan al umbral de confianza, obtenemos unos
resultados mas coherentes con la complejidad teorica ademas de unos tiempos de ejecucion hasta un 72% mas rapidos, como ocurre en
el algoritmo fib3.
